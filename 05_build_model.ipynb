{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e871bbb4-4531-47d5-ac15-118ce63b132f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30d98a1-e543-4f4e-98a5-62a025c82229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eeb962a0-377a-48dd-b9da-1ea76fc82c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d867612-fac1-4203-a1fd-dea063c474fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.12.1'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da891472-0fab-4729-8a90-7b86639274d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()  # start dim = 1\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 512), \n",
    "            nn.ReLU(), \n",
    "            nn.Linear(512, 10), \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a5388c0-7636-446e-a536-f0eeca4db8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85ff9cb-62bf-41a0-a15e-28fe4a05703e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3654e-01, 6.0849e-01, 4.3281e-01, 5.7581e-01, 5.5888e-02,\n",
       "          6.2762e-01, 2.8965e-03, 6.6817e-01, 5.0711e-01, 5.4059e-01,\n",
       "          5.0116e-01, 5.0628e-01, 7.6455e-01, 9.3490e-01, 2.7472e-01,\n",
       "          5.4582e-01, 8.9167e-02, 8.8430e-02, 4.7153e-01, 7.8757e-01,\n",
       "          1.9433e-01, 4.1996e-01, 8.2949e-01, 2.1357e-02, 1.8820e-01,\n",
       "          1.4203e-01, 9.3706e-01, 5.3404e-02],\n",
       "         [3.8734e-01, 3.7776e-02, 6.9770e-01, 1.3807e-01, 1.3632e-01,\n",
       "          7.8843e-01, 8.1617e-01, 9.8317e-01, 8.6007e-01, 7.3541e-01,\n",
       "          6.7427e-01, 6.1210e-01, 9.4423e-01, 8.3802e-01, 9.7314e-02,\n",
       "          1.2987e-01, 8.3355e-01, 3.7858e-01, 5.3575e-01, 2.7350e-01,\n",
       "          9.8886e-01, 8.4706e-01, 7.9903e-01, 5.5084e-03, 2.6210e-01,\n",
       "          8.0432e-01, 8.8383e-01, 3.2613e-01],\n",
       "         [9.6638e-01, 8.7985e-01, 1.0334e-01, 4.9691e-01, 8.1116e-01,\n",
       "          4.3581e-01, 9.4894e-01, 7.4040e-01, 4.3424e-02, 8.4076e-01,\n",
       "          3.4638e-01, 3.4871e-01, 2.2971e-01, 8.1079e-01, 8.9857e-01,\n",
       "          3.2075e-01, 9.3203e-01, 8.2766e-01, 5.7027e-01, 4.7084e-01,\n",
       "          5.4412e-02, 2.0229e-01, 2.2560e-01, 4.0068e-01, 6.0061e-01,\n",
       "          6.2237e-01, 7.1263e-01, 8.3524e-01],\n",
       "         [9.6900e-01, 3.0931e-01, 6.9072e-01, 9.4158e-02, 6.7594e-01,\n",
       "          4.1302e-01, 8.6256e-01, 9.7024e-02, 7.6549e-01, 5.3712e-01,\n",
       "          3.5265e-01, 1.9353e-01, 3.5262e-01, 1.3587e-01, 9.3758e-01,\n",
       "          8.5250e-01, 3.8394e-01, 1.5502e-03, 4.2240e-01, 6.1075e-01,\n",
       "          9.9767e-01, 5.9844e-01, 5.5839e-01, 2.1842e-02, 4.0503e-01,\n",
       "          3.7588e-01, 7.6696e-01, 1.6785e-01],\n",
       "         [9.7124e-01, 4.5005e-01, 5.8630e-01, 8.9816e-01, 5.2194e-01,\n",
       "          8.2416e-01, 2.4272e-04, 9.4431e-01, 2.6858e-01, 2.1582e-01,\n",
       "          2.5250e-01, 2.0635e-01, 4.7876e-01, 8.2287e-02, 6.4114e-01,\n",
       "          5.2822e-01, 9.3978e-01, 2.8246e-01, 7.0893e-01, 1.3659e-01,\n",
       "          7.4716e-01, 4.2392e-01, 4.6747e-01, 8.4675e-01, 3.8227e-01,\n",
       "          8.7980e-01, 8.7793e-01, 9.3677e-01],\n",
       "         [2.1387e-01, 9.2508e-01, 4.8131e-01, 9.3898e-01, 8.3194e-01,\n",
       "          5.6016e-01, 7.1423e-01, 4.7024e-01, 4.6697e-01, 9.3970e-02,\n",
       "          6.6911e-01, 5.3193e-01, 4.0016e-01, 8.5525e-01, 4.7575e-01,\n",
       "          4.9644e-01, 1.5760e-01, 2.3537e-01, 3.8848e-01, 5.8405e-01,\n",
       "          6.4597e-01, 1.4602e-01, 9.1291e-01, 9.0321e-01, 3.3265e-01,\n",
       "          9.9253e-01, 1.8820e-01, 5.4284e-01],\n",
       "         [8.8382e-01, 6.0085e-01, 3.1122e-01, 1.8836e-02, 5.0139e-01,\n",
       "          5.9255e-02, 6.3686e-01, 5.0623e-01, 2.8292e-01, 9.1734e-01,\n",
       "          5.0715e-01, 3.6241e-01, 3.4467e-03, 3.2271e-01, 6.0441e-01,\n",
       "          1.0628e-01, 4.8828e-01, 9.4432e-01, 1.9931e-01, 9.6442e-01,\n",
       "          7.1954e-01, 5.2142e-01, 4.9926e-01, 1.4910e-01, 1.2497e-01,\n",
       "          1.2778e-01, 2.1882e-02, 3.8273e-01],\n",
       "         [1.0178e-01, 4.8247e-01, 4.8217e-01, 6.5216e-02, 9.8507e-01,\n",
       "          7.2958e-01, 7.4377e-01, 5.4996e-01, 6.8223e-01, 7.3443e-01,\n",
       "          2.8682e-01, 1.3760e-02, 7.1780e-01, 4.3302e-01, 7.8619e-01,\n",
       "          6.8844e-01, 8.1479e-01, 5.6431e-01, 7.3434e-01, 8.0507e-01,\n",
       "          8.3436e-01, 8.0434e-01, 2.4349e-01, 7.0175e-01, 2.0131e-01,\n",
       "          9.2752e-02, 6.2087e-01, 9.3598e-01],\n",
       "         [8.6314e-01, 7.8556e-01, 6.2091e-01, 4.5182e-01, 6.6842e-01,\n",
       "          6.3423e-01, 1.9244e-01, 7.0145e-01, 1.2107e-03, 9.8818e-01,\n",
       "          3.8693e-01, 6.5576e-01, 5.4153e-01, 3.6270e-02, 7.4457e-01,\n",
       "          3.9594e-01, 5.0195e-01, 7.3902e-01, 7.3120e-02, 3.4896e-01,\n",
       "          3.1013e-01, 1.2328e-01, 8.7370e-01, 5.2722e-01, 2.0059e-01,\n",
       "          2.5587e-01, 2.2507e-01, 2.2119e-01],\n",
       "         [7.9952e-01, 6.7573e-01, 7.8531e-02, 2.9711e-02, 7.8668e-01,\n",
       "          7.7971e-01, 4.5020e-01, 3.0666e-01, 9.0576e-01, 6.9404e-01,\n",
       "          1.7265e-01, 4.0457e-01, 2.4858e-01, 5.4862e-01, 9.8631e-01,\n",
       "          5.8103e-02, 8.5424e-01, 2.6717e-01, 3.2028e-01, 8.7650e-01,\n",
       "          1.3096e-01, 6.8177e-01, 7.6447e-01, 4.8791e-01, 2.2908e-01,\n",
       "          1.4054e-01, 7.3054e-01, 7.4059e-02],\n",
       "         [2.7705e-01, 5.9299e-01, 9.4412e-01, 4.2914e-01, 2.7414e-01,\n",
       "          5.6867e-01, 6.2236e-01, 6.6178e-02, 8.2487e-02, 2.2175e-01,\n",
       "          2.2009e-01, 8.1375e-01, 8.4200e-01, 4.0808e-01, 9.2360e-01,\n",
       "          6.9348e-01, 8.1030e-01, 5.5180e-02, 7.0328e-01, 3.5703e-02,\n",
       "          9.5578e-01, 4.9198e-01, 6.1790e-02, 8.7653e-01, 8.2396e-01,\n",
       "          3.4894e-03, 9.5437e-02, 6.8503e-01],\n",
       "         [9.6694e-01, 6.1677e-01, 1.1744e-01, 1.0115e-01, 7.9352e-01,\n",
       "          4.3199e-01, 9.5434e-01, 3.1435e-01, 3.0195e-01, 6.4070e-01,\n",
       "          8.3012e-02, 7.6948e-01, 4.8710e-01, 8.6178e-01, 3.6246e-01,\n",
       "          2.3231e-01, 8.9228e-01, 3.7932e-01, 4.7638e-01, 5.1375e-01,\n",
       "          4.2938e-01, 4.2228e-01, 1.8143e-01, 1.0389e-01, 6.3091e-01,\n",
       "          5.0531e-01, 6.7105e-01, 6.4497e-02],\n",
       "         [7.6146e-01, 8.4150e-02, 6.4537e-01, 9.3648e-01, 9.1316e-01,\n",
       "          4.4837e-01, 5.8276e-01, 3.4648e-02, 5.0228e-01, 2.0967e-01,\n",
       "          1.9643e-01, 7.7510e-01, 5.4792e-01, 7.9863e-01, 4.4281e-01,\n",
       "          2.3633e-01, 3.3029e-01, 1.9499e-01, 7.7398e-01, 7.1034e-01,\n",
       "          6.2021e-01, 1.8230e-01, 9.3987e-01, 4.8731e-01, 6.7767e-01,\n",
       "          1.7430e-02, 3.5128e-02, 6.2405e-01],\n",
       "         [6.2931e-01, 3.6450e-01, 9.0379e-01, 1.5437e-02, 3.1022e-01,\n",
       "          3.8641e-01, 1.6350e-01, 2.8395e-01, 9.7318e-01, 1.2058e-01,\n",
       "          5.5847e-02, 5.8213e-01, 3.3366e-01, 6.8938e-01, 2.3462e-01,\n",
       "          8.8427e-01, 4.5945e-01, 4.5358e-01, 2.8070e-01, 6.4963e-01,\n",
       "          3.6913e-01, 6.4249e-01, 5.5018e-01, 7.8129e-01, 3.4287e-02,\n",
       "          9.5684e-01, 1.4695e-01, 6.1581e-01],\n",
       "         [8.3679e-01, 9.6117e-01, 2.5369e-01, 4.0429e-01, 4.1681e-01,\n",
       "          2.9627e-01, 1.5546e-01, 8.9165e-01, 3.2138e-01, 1.1960e-01,\n",
       "          1.0355e-01, 1.2007e-01, 8.4059e-01, 7.4032e-01, 2.8088e-01,\n",
       "          2.4700e-01, 6.8679e-01, 6.6044e-01, 8.0601e-01, 1.5939e-01,\n",
       "          8.8095e-01, 3.0923e-01, 2.5538e-02, 3.3173e-01, 6.7292e-01,\n",
       "          1.1017e-01, 8.1651e-01, 1.1073e-01],\n",
       "         [4.7428e-01, 5.3257e-01, 6.4881e-01, 1.2767e-01, 9.5032e-01,\n",
       "          3.2234e-01, 1.9032e-02, 6.7727e-01, 9.7763e-01, 3.9771e-01,\n",
       "          2.7147e-01, 2.7557e-01, 8.0300e-01, 6.0417e-01, 6.5754e-02,\n",
       "          8.3584e-01, 4.8109e-01, 6.7911e-01, 9.4481e-01, 1.3141e-01,\n",
       "          8.9744e-01, 2.7351e-01, 8.8218e-01, 9.8286e-01, 4.7954e-01,\n",
       "          6.7123e-01, 1.7524e-01, 6.7707e-01],\n",
       "         [6.1389e-01, 6.4725e-01, 6.0530e-01, 6.8578e-01, 5.3662e-01,\n",
       "          6.9192e-01, 9.4341e-01, 8.2979e-01, 4.2511e-01, 5.1975e-01,\n",
       "          2.8260e-01, 4.8897e-01, 4.9669e-01, 3.8025e-01, 7.8125e-01,\n",
       "          6.0399e-01, 9.7290e-02, 9.4945e-01, 9.1533e-01, 4.9789e-01,\n",
       "          5.7081e-01, 9.1647e-02, 1.3065e-01, 1.4458e-01, 6.3315e-01,\n",
       "          8.4713e-01, 7.9071e-01, 9.2645e-01],\n",
       "         [8.5269e-01, 5.7406e-01, 3.6358e-01, 5.6144e-01, 2.0488e-01,\n",
       "          9.1223e-01, 5.9239e-01, 3.5861e-01, 5.0986e-01, 8.3693e-01,\n",
       "          8.2209e-01, 4.4225e-01, 8.5896e-01, 4.1200e-01, 2.4196e-01,\n",
       "          5.6665e-02, 9.4032e-01, 2.5261e-01, 1.1561e-02, 6.8931e-01,\n",
       "          6.5088e-01, 8.1114e-01, 8.3139e-01, 6.5043e-01, 8.8390e-02,\n",
       "          9.0851e-01, 2.5895e-01, 3.3122e-01],\n",
       "         [5.9577e-01, 3.2579e-02, 8.8176e-01, 6.4476e-01, 3.2415e-01,\n",
       "          4.5214e-01, 1.3539e-01, 9.8897e-01, 7.5361e-01, 8.4059e-01,\n",
       "          7.9279e-01, 7.8345e-01, 7.9373e-01, 1.7666e-01, 8.9845e-01,\n",
       "          9.1525e-01, 5.1677e-01, 2.1513e-01, 7.4120e-01, 5.2015e-01,\n",
       "          1.2388e-01, 5.7815e-01, 1.1055e-01, 8.2861e-01, 2.1072e-01,\n",
       "          3.4093e-01, 6.8782e-01, 4.6527e-01],\n",
       "         [2.0455e-01, 1.6509e-01, 2.4068e-01, 9.2578e-02, 8.9591e-01,\n",
       "          3.7217e-01, 8.1872e-01, 9.5152e-02, 7.7021e-03, 2.6357e-02,\n",
       "          3.6100e-01, 2.1922e-01, 1.2601e-01, 9.0907e-01, 4.3599e-01,\n",
       "          3.1185e-01, 1.9653e-02, 7.3866e-01, 2.0346e-01, 7.6361e-01,\n",
       "          4.3417e-01, 9.5363e-01, 2.5725e-01, 6.5982e-01, 3.1850e-01,\n",
       "          5.6560e-01, 5.5152e-01, 5.8140e-01],\n",
       "         [9.4384e-02, 9.5274e-01, 3.7583e-01, 2.1739e-02, 9.6160e-01,\n",
       "          4.7904e-01, 1.3296e-01, 6.4832e-01, 9.7340e-01, 3.5365e-01,\n",
       "          2.2046e-01, 6.4511e-02, 3.0436e-01, 9.5383e-01, 1.0495e-01,\n",
       "          7.3909e-01, 4.3761e-01, 4.5329e-01, 1.4091e-01, 5.1691e-01,\n",
       "          2.5226e-01, 3.5391e-01, 7.3500e-02, 5.7884e-01, 1.1754e-01,\n",
       "          1.9476e-01, 2.6187e-01, 4.9078e-01],\n",
       "         [5.0708e-01, 2.6012e-01, 6.3890e-01, 5.3404e-01, 7.7453e-01,\n",
       "          8.3023e-01, 1.8347e-01, 8.8019e-01, 8.2097e-01, 6.2804e-01,\n",
       "          1.2099e-01, 5.2960e-01, 4.3455e-01, 1.6918e-01, 8.9945e-01,\n",
       "          4.6303e-01, 2.4895e-01, 6.5966e-01, 6.2949e-01, 3.5056e-01,\n",
       "          4.4959e-01, 1.1914e-01, 5.1304e-01, 3.8173e-01, 9.2227e-01,\n",
       "          9.5658e-01, 7.4686e-01, 7.3584e-01],\n",
       "         [3.4818e-01, 5.6604e-01, 9.1060e-01, 9.2902e-01, 9.6696e-01,\n",
       "          7.3518e-01, 9.4571e-01, 9.5183e-01, 1.0828e-01, 1.5033e-01,\n",
       "          6.2920e-01, 5.8070e-01, 9.9261e-01, 8.9775e-01, 9.3798e-01,\n",
       "          5.2974e-01, 8.9189e-01, 1.2945e-01, 4.8715e-01, 2.6387e-01,\n",
       "          6.4686e-03, 9.5729e-01, 5.7006e-01, 5.0785e-01, 1.8871e-01,\n",
       "          4.0409e-01, 5.9846e-03, 1.0632e-01],\n",
       "         [8.9259e-01, 9.7781e-01, 7.9732e-01, 9.5550e-01, 3.4476e-02,\n",
       "          8.1511e-01, 1.0835e-01, 7.1411e-01, 6.8156e-02, 8.1247e-01,\n",
       "          8.9893e-01, 2.2186e-01, 7.4733e-01, 7.5278e-01, 6.4528e-01,\n",
       "          4.2297e-01, 4.3858e-01, 2.7470e-01, 3.6853e-01, 2.2413e-01,\n",
       "          8.2852e-02, 4.6306e-01, 2.9841e-01, 9.3602e-01, 8.8050e-01,\n",
       "          5.4712e-01, 6.3965e-01, 9.1235e-01],\n",
       "         [4.8260e-02, 7.8825e-02, 7.3556e-01, 8.4888e-01, 9.9382e-02,\n",
       "          8.4236e-01, 3.4313e-01, 7.2799e-01, 5.0143e-01, 1.4307e-01,\n",
       "          7.7280e-01, 3.8092e-01, 5.7169e-01, 3.8244e-01, 8.8487e-01,\n",
       "          8.3249e-01, 8.1041e-01, 5.6337e-01, 4.3490e-01, 8.5090e-01,\n",
       "          4.0298e-01, 7.4844e-01, 1.5486e-01, 4.5978e-02, 4.1653e-01,\n",
       "          2.7213e-01, 6.5861e-01, 3.4691e-01],\n",
       "         [2.5126e-01, 5.2620e-01, 4.4971e-02, 1.1827e-01, 9.9038e-01,\n",
       "          9.7184e-02, 8.3695e-01, 5.3635e-02, 8.5084e-01, 1.8032e-01,\n",
       "          3.1889e-01, 5.7156e-01, 6.3817e-01, 2.4511e-01, 8.7422e-01,\n",
       "          8.7581e-01, 1.7621e-01, 3.7489e-01, 4.2239e-01, 9.6983e-01,\n",
       "          5.6540e-01, 1.7676e-01, 9.4148e-01, 8.7580e-01, 8.3717e-02,\n",
       "          9.8015e-01, 3.9719e-01, 8.3088e-01],\n",
       "         [4.6419e-02, 9.0235e-01, 7.6968e-01, 4.7871e-01, 1.2413e-01,\n",
       "          1.9311e-01, 7.0810e-01, 3.3939e-01, 3.7910e-01, 9.3025e-01,\n",
       "          7.7305e-01, 3.2479e-01, 2.0009e-01, 4.8876e-01, 7.8605e-01,\n",
       "          3.2240e-01, 1.1848e-01, 5.6992e-01, 5.9045e-01, 4.9953e-02,\n",
       "          1.8954e-01, 5.4108e-01, 2.3776e-01, 7.4011e-01, 5.3145e-03,\n",
       "          2.3450e-02, 3.4956e-01, 8.6489e-01],\n",
       "         [1.7785e-01, 7.1313e-01, 2.3555e-01, 8.1771e-01, 3.9980e-01,\n",
       "          8.0457e-01, 7.4391e-01, 2.8478e-02, 9.9913e-01, 8.5217e-01,\n",
       "          9.0289e-01, 2.7403e-01, 7.3352e-01, 2.6471e-02, 1.4392e-01,\n",
       "          9.5620e-01, 4.4075e-01, 4.8008e-01, 2.7164e-01, 4.4375e-01,\n",
       "          9.7130e-01, 4.9306e-01, 7.0401e-01, 1.3687e-01, 8.0833e-01,\n",
       "          8.5758e-01, 8.4930e-01, 4.4329e-01]]], device='cuda:0')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand((1, 28, 28), device=device)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "600aa99a-54d7-4239-8f81-820443fe84d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46959f5e-60a0-4bf3-9ec1-b2f094e49a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1199,  0.0102, -0.0337, -0.0741, -0.1079,  0.0557,  0.1443,  0.1039,\n",
       "          0.0513, -0.0376]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = model(x)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bbe25e7-91ea-45ab-9336-2e660b071a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86787a62-8ea7-4d2c-9a24-4b351f078a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0885, 0.1007, 0.0964, 0.0926, 0.0895, 0.1054, 0.1152, 0.1106, 0.1050,\n",
       "         0.0960]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = nn.Softmax(1)(output)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75e2c6ac-0f03-4bf6-bf52-5dfcea70bd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = pred.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a86a71c3-f36b-4b36-91e3-86b2cf87417e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6], device='cuda:0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9ac15e0-9b31-4c46-b52f-07e37403be35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(res.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "044c0183-ffe5-464e-9f62-2a4d82d8f0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1dc13405-bc9b-4651-823c-abcece8bca97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a045f7e-0757-4ce3-aba1-ef0add29e51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "NeuralNetwork                            [16, 10]                  --\n",
       "├─Flatten: 1-1                           [16, 784]                 --\n",
       "├─Sequential: 1-2                        [16, 10]                  --\n",
       "│    └─Linear: 2-1                       [16, 512]                 401,920\n",
       "│    └─ReLU: 2-2                         [16, 512]                 --\n",
       "│    └─Linear: 2-3                       [16, 512]                 262,656\n",
       "│    └─ReLU: 2-4                         [16, 512]                 --\n",
       "│    └─Linear: 2-5                       [16, 10]                  5,130\n",
       "==========================================================================================\n",
       "Total params: 669,706\n",
       "Trainable params: 669,706\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 10.72\n",
       "==========================================================================================\n",
       "Input size (MB): 0.05\n",
       "Forward/backward pass size (MB): 0.13\n",
       "Params size (MB): 2.68\n",
       "Estimated Total Size (MB): 2.86\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(16, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "36008b89-179e-4591-902b-bf55f187e2ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure: NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0292,  0.0342, -0.0269,  ...,  0.0141,  0.0030, -0.0276],\n",
      "        [-0.0061, -0.0081, -0.0155,  ...,  0.0031, -0.0124,  0.0080]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0291, -0.0051], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0330,  0.0219,  0.0303,  ...,  0.0277, -0.0145,  0.0035],\n",
      "        [-0.0062, -0.0435, -0.0365,  ...,  0.0406,  0.0416,  0.0060]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0291, -0.0411], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0305,  0.0401, -0.0198,  ..., -0.0355, -0.0334, -0.0326],\n",
      "        [ 0.0301, -0.0223,  0.0331,  ...,  0.0359,  0.0293,  0.0174]],\n",
      "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0307, 0.0345], device='cuda:0', grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model structure: {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2ffbf-1b56-4c8e-8ca3-d8ab18c4be9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
